---
  output: html_document
---
  
  <img style="float:right;padding-right:25px;border:none" src="https://upload.wikimedia.org/wikipedia/en/thumb/e/e3/GMU_logo.svg/1280px-GMU_logo.svg.png" height="150px" width = "150px"/>
  
  <img align = "right" src="https://upload.wikimedia.org/wikipedia/en/6/6a/Smithsonian_Conservation_Biology_Institute_logo.png" height="150px" width = "150px"/>
  
# Data manipulation with tidyr and dplyr
##_The grammar of data wrangling_
_Brian S. Evans  
Smithsonian Conservation Biology Institute  
Migratory Bird Center_    
_Note: This lesson borrows **heavily** from Hadley Wickham's awesome paper on Tidy Data (2014). We strongly recommend this paper to all R users!_

----

## Before you begin
Copy-paste-and run the following code in R Studio to load the packages and read in the data we will be using for this lesson:

```{r, eval=TRUE, message=FALSE, warning=FALSE}
library(RCurl)

url <-'https://raw.githubusercontent.com/SCBI-MigBirds/MigBirds/master/source/sourceDataManip.R'
sourceURL <- getURL(url)

eval(parse(text = sourceURL))
```

----

## Introduction

  It is estimated that the process of preparing data for analysis, **data manipulation** or, as Hadley Wickham has called it, **data wrangling**, consumes up to 80 percent of total analysis time (Dasu and Johnson 2003).  In classes on statistics and applied data analysis, emphasis is generally placed on the analysis of data and, historically, comparatively little attention is paid to how to prepare one's data to be analyzed. With increasing calls for reproducibility, however, this is beginning to change. Increasingly, journals are asking authors to publish both data and R code as supplemental information for their manuscripts. This helps advance scientific knowledge, as researchers do not have to reinvent the wheel every time they conduct a similar analysis, and ensures replicability, as interested parties (e.g., reviewers) can repeat your every step in your data analysis with the exception of the collection of field data! Considering this, it is in all of our best interest that data manipulation <img style="PADDING-RIGHT:40px; PADDING-TOP: 10px; PADDING-BOTTOM: 15px" align = "left" src="http://images.nationalgeographic.com/wpf/media-live/photos/000/183/cache/upside-down-bird_18378_990x742.jpg" height="400px" width = "400px" title=" Hideta Nagai, National Geographic"> be simple, that our scripts are legible and easy-to-follow, and that we can avoid "script bloat" by using methods (such as functions and occasionally _for loops_!) to reduce the length of our scripts. It is highly recommended that you take a "cradle-to-grave" approach to data manipulation and analysis:

1) Collect and store your data in well-constructed spreadsheets and databases. 
2) DO NOT complete ANY step in the data manipulation process in Excel! Doing so makes it difficult for others to truly replicate your analyses.
3) Basic formatting steps to prepare your data for analysis, **data tidying**, should be completed prior to any summarizing, further cleaning, or analysis of data.
4) Clean data, including removing "bad" records, such as NA values (i.e., "Not Available") and extreme outliers, prior to (not during) analysis. 
5) Group and summarize data as a final step the final data exploration and formatting processes -- prior to more complex statistical analyses.

    
----

## Tidy data

A tidy dataset basically has two qualities -- each row is an observation and each variable is placed in its own column. If you're anything like me, you likely read the last sentence and thought to yourself "well, that's pretty darned obvious -- I don't think I've ever made, nor would I ever make, make an untidy dataset in the first place!" Chances are, you are wrong just as I was. Untidy datasets are more common than you might think -- you have likely made an untidy dataset or two! Below is a typical example in which  the influence of a treatment was measured on three test subjects and the results were stored as:

```{r, eval = T, echo=FALSE}
untidyFrame
```

Tidy? Nope. In this case, each subject has its own row, not each observation. We would have to do some awkward wrangling in base R to get this into a tidy format. Luckily, Hadley Wickham (have we mentioned that we're wicked fans of Hadley Wickham? If not, we will ...) created the `tidyr` package in R with the specific aim of turning messy datasets into tidy ones.

```{r, eval = T, echo=TRUE, warning=FALSE}
library(tidyr)
```

With the `tidyr` function `gather`, we collapse multiple columns into "key-value pairs". In the above example, we are interested in the treatment "values" for each of our "key" values. To do so, we provide:

1. The data frame ("untidyFrame") we will be reshaping
2. The name of the new "key" field for which we are gathering the data ("treatment")
3. The name of the new "value" field where the values for that field will be stored
4. The columns for which the values will be restructured (these may be referred to by name or column number)

```{r, eval = T, echo=TRUE}
tidyFrame <- gather(data = untidyFrame, 
  key = treatment, 
  value = value, 
  treatmentA:treatmentB)

tidyFrame
```

Let's give a more bird-y example. I (Brian) collected point count data from sites in Washington, D.C. For each bird, I calculated the distance between myself and the observed birds, in units of 10 meters. On my datasheet I recorded the following:

```{r, eval = T, echo=F, warning=FALSE}
wideFrame
```

In the above, each bird is certainly an observation, but is each distance class (which represents 10 to 30 m from the point count location) truly a separate variable? Nope. As such, we are compelled to tidy our data by collapsing the distances into an individual column. In the script below we use the `tidyr` function `gather` as:

```{r, eval = TRUE, echo=TRUE}
tidyCounts <- gather(data = wideFrame, 
  key = distance,
  value = obs, 
  d10:d30)

tidyCounts
```

The above is what is often called a "**long**" data frame. Are all tidy data frames long? Not necessarily! That depends on the observational unit of your study. If your observational unit is individual birds or birds at a given distance class, it may be more appropriate for your data to be arranged in long format. If, however, you are studying bird community composition at a number of sites
it may be appropriate to consider sites as the unit of observation and species as variables -- thus data are arranged in "**wide**" format. To account for this, you could always arrange your point count data sheets with each column representing each species that you might possibly encounter at every site of your study ... but then, of course, you'd be crazy. In this instance, the sane among you would collect your data in long format and use wide format for your tidy frame. Let's consider the following count data:

```{r, eval = T, echo=F, warning=FALSE}
longFrame
```

Thus, for many community data analyses, sites may be considered the observational units with species listed as columns. To convert this from a long to a wide frame, we use the `spread` function in `tidyr`:

```{r, eval = T, warning=FALSE}
spread(longFrame, species, count)
```

Well, there's a problem with the above. Do the NA values above (Not Available) really mean NA? Technically, zero observations are zeroes, with NA's constrained to unsampled data. Luckily we can "fill" the NA values with zeroes as below:

```{r, eval = T, warning=FALSE}
spread(longFrame, species, count, fill = 0)
```


For the sake of brevity, we'll leave tidying data to just these two functions. There are a few other functions in `tidyr` (I strongly suggest reading Wickham's [Tidy Data](http://www.jstatsoft.org/v59/i10/paper) (2014) paper), but you'll have to explore those on your own to give us some time to explore the wonderful world of `dplyr`!

----

> **Exercise 1**    
> The dataset "birdCounts" is located in your global environment. Using these data:
>
> 1. Convert birdCounts to a wide format dataset, setting NA values to 0. Assign the name "wideBirds" to this data frame.
> 2. Convert wideBirds to a tidy long format dataset. Assign the name "longBirds" to this data frame.
> 3. Use the `head` function to compare the birdCounts data frame and "longBirds".

----

## dplyr

**dplyr** makes data manipulation simple by using just a few basic functions that satisfy most data manipulation tasks. It is considerably faster than most other data manipulation, which can be quite important when analyzing big data.

* **filter**: Remove rows that do not match a certain criteria

* **select**: Remove or maintain columns in a data set

* **arrange**: Reorder rows

* **mutate**: Create new variables

* **summarize**: Calculate a summary statistic -- this is most useful (or, perhaps, only useful) in combination with the function `group_by`.

### Subset data by observations

In our Introduction to R lesson, we subset the bird count rows using indexing. For example to view the counts of just foliage foraging species we enter:

```{r eval = F}
birdCounts[birdCounts$foraging == 'foliage',]
```

The `filter` fuction in `dplyr` works similarly, but the script is more concise:

```{r eval = F}
filter(birdCounts, foraging == 'foliage')
```

Note that the left side of the argument above is the data frame we are subsetting and the right hand of the argument is the logical condition. Because we have already specified the data frame from which we are filtering, it is not necessary to provide the name of the data frame within the logical condition.

The advantage of this becomes readily apparent when we are filtering based on multiple conditions. Consider we would like to subset our birdCounts frame to foliage foraging species with an omnivorous diet. Let's compare the indexing and `dplyr` solution.

```{r eval = F}

birdCounts[birdCounts$foraging == 'foliage' & birdCounts$diet == 'omnivore',]

filter(birdCounts, foraging == 'foliage' & diet == 'omnivore')

```

And the advantage builds as we increase the number of selection criteria:


```{r eval = F}

birdCounts[birdCounts$foraging == 'foliage' & birdCounts$diet == 'omnivore' & birdCounts$count > 1,]

filter(birdCounts, foraging == 'foliage' & diet == 'omnivore' & count > 1)

```

----

> <img style="PADDING-RIGHT:25px; PADDING-TOP: 0px; PADDING-BOTTOM: 5px" align = "left" src="http://www.allaboutbirds.org/guide/PHOTO/LARGE/carolina_chickadee_4.jpg" height="175px" width = "175px" title="Michael Drummond">
> **Exercise 2**    
Subset the birdCounts data frame to observations of Carolina Chickadee (_Poecile carolinensis_) in which two or more individuals were observed using:    
1. indexing    
2. dplyr's filter command  
>
    
----
    
### Subset data by columns

In our Introduction to R lesson we learned how to select columns from a data frame using indexing. We can select columns based on their position within the data frame or by name:

```{r eval = F}

# By position: 

birdCounts[,3:4]

# By name:

birdCounts[, c('count', 'foraging')]

```

We can use the `select` function in `dplyr` to select columns as well:

```{r eval = F}

# By position: 

select(birdCounts, 3:4)

# By name:

select(birdCounts, count, foraging)
```

The `select` function is more flexible than indexing, in that column names can be used in place of numbers to select a range of columns:

```{r eval = F}
select(birdCounts, count:diet)

```

To remove a column, you would use a minus sign:

```{r eval = F}
select(birdCounts, -site)

```

----

> **Exercise 3**    
> 1. Use the `select` function to subset the birdCounts data frame to species, count, and diet guild columns. Assign the name "birdCount1" to this data frame.    
2. Use the `filter` function to subset your reduced data frame to observations of omnivores and granivores. Assign the name "birdCount2" to this data frame.    
3. Use the `filter` function to subset  birdCount2 to counts that are greater than or equal to three individuals.
>

----

### Arrange data in ascending or descending order

`dplyr` contains a handy function, `arrange` to sort data frames in ascending (low-to-high) or descending (high-to-low) order.
For example, if you wanted to arrange the birdCounts data frame by count:

```{r eval = F}

# Ascending:

arrange(birdCounts, count)

# Descending:

arrange(birdCounts, desc(count))

```

`arrange` also works with characters and factors to arrange alphabetically:

```{r, eval = F}
arrange(birdCounts, species)
```

This can be used in combination with another `dplyr` function, `distinct`, which removes duplicate observations from a data frame. For example, let's use `select`, as above, to create a reduced data frame that contains only species, `distinct` to remove all duplicate observations, and arrange the species names alphabetically:

```{r eval = F}

# Subset birdCounts to only the species column:

birdCountsSp <- select(birdCounts, species)

# Use distinct to remove duplicate rows:

birdCountsSpDistinct <- distinct(birdCountsSp)

# Arrange alphabetically

arrange(birdCountsSpDistinct, species)

```

----

> **Exercise 4**        
> 1. Subset birdCounts data frame to only species and diet fields. Assign the name "birdCountSpDiet" to this data frame.        
2. Subset the dataset to only insectivorous species. Assign the name "birdCountInsect" to this data frame.       
3. Use `distinct` to remove duplicate observations. Assign the name "birdCountInsectDistinct" to this data frame.
4. Use `arrange` to sort the species column alphabetically.
>

----

### Create new variables

We can use the `dplyr` function `mutate` to add new derived variables to our data frame. For example, we can calculate the percentile ranks of our count column and give our new column the name "pRank" (admittedly not a very useful summary statistic at this juncture!):

```{r, eval = F}
birdCountsPrank <- mutate(birdCounts, pRank = percent_rank(count))
``` 

----

> **Exercise 5**    
> The `paste` function in base R is used to concatenate character values (_Note: the syntax is `paste(column1, column2)`_). Use mutate and the paste function to create a new column names "forDiet" in the birdCountsPrank data frame that concatenates values in the foraging and diet vectors.
>

----

### Summarize data

The biggest asset of `dplyr` is that it provides a flexible and memory efficient tool for summarizing data, the function `summarize`. `summarize` allows you to calculate summary statistics across a data frame. For example, to calculate the sum of counts, you would use:

```{r, eval = F}
summarize(birdCounts, sum(count))
``` 

This may seem (on its surface) a bit silly, as you could have gotten the same result as above using:

```{r, eval = F}
sum(birdCounts$count)
``` 

On it's own, `summarize` is obviously really not very useful. In combination with the `dplyr` function `group_by`, however, `summarize` becomes a powerful tool. First, let's look at what happens to our bird count dataset when we use the `group_by` function on the foraging field:

```{r, eval = F}
group_by(birdCounts, foraging)
``` 

Compare the output of this function with the birdCounts data frame:

```{r, eval = F}
birdCounts
``` 

You'll notice that the data frame itself wasn't changed, but there is additional output ... "Groups". 

You can use this grouping to calculate the summary statistics across groups. For example, let's create a new data frame called "birdCountsForaging" and calculate the total counts for each foraging guild:

```{r, eval = F}
birdCountsForaging <- group_by(birdCounts, foraging)

summarize(birdCountsForaging, N = sum(count))
``` 

We can also group and summarize by multiple groups:


```{r, eval = F}
birdCountsForagingDiet <- group_by(birdCounts, foraging, diet)

summarize(birdCountsForagingDiet, N = sum(count))
``` 

This function is phenomenally powerful and memory efficient. In fact, the `summarize` function in `dplyr` has been found to be a whopping 10,000 times more memory efficient than the equivalent function in Hadley Wickham's `plyr` package, which itself is more memory effient than most of the other data summary methods out there!

----

> **Exercise 6**    
> 1. Group birdCounts by species.  Assign the name "birdCountSp" to this data frame.    
> 2. Calculate the sum total of counts for each species. Assign the name "birdCountSpSum" to your summary data frame and N to your count vector.    
> 3. Sort birdCountSpSum from highest to lowest count.

----

## The **pipe** operator

One of the greatest recent advancements in the world of R is the implementation of the **pipe operator**. A pipe operator allows you to set the output of one process as the input of another -- thus sequences of calculations are chained together without having to define intermediate steps as R objects (_Note: Piping is sometimes called chaining_). Piping was first implemented in R by ecologist and R guru Ben Bolker, in an answer to a question on stackoverflow. <img style="PADDING-LEFT:25px; PADDING-TOP: 5px" align = "right" src="https://upload.wikimedia.org/wikipedia/en/b/b9/MagrittePipe.jpg" height="300px" width = "300"/>  Hadley Wickham introduced his version of piping to his `dplyr` package in 2013 while concurrently Stefan Milton Bache developed a more flexible version for his package `magrittr` (named after Magritte's painting, _The Treachery of Images_). In 2014, Wickham and Bache teamed up and Bache's pipe was incorporated into `dplyr`.

Piping makes scripts more readable (see a pattern here?) and saves system memory by reducing the amount of data stored in R's Global Environment. Take a moment to look at your Global Environment (upper right-hand pane in R Studio). You've got lots of objects in there. Likewise, if you didn't do a great job naming your R objects, you may have a hard time remembering what each was. Piping avoids the necessity to assign intermediate objects by conducting an analysis in sequence. Let's look at our `dplyr` summarizing operation above, first without and then with piping.

```{r, eval = F}
birdCountsForaging <- group_by(birdCounts, foraging)

summarize(birdCountsForaging, N = sum(count))
``` 

To pipe this operation, we use the `%>%` symbol, which can be thought of as the word "then" ... in other words, first this, then that.

```{r, eval = F}
birdCounts %>% 
  group_by(foraging) %>%
  summarize(N = sum(count))
```

Notice in the above that I first defined the data frame we were using. This allowed me to omit the name of the data frame in the subsequent steps. Also notice that I used multiple lines of code. For maximal readibility, it is **highly recommended** that any multi-step operation should be formatted as such (this is considered **best management practices** for programmers across languages).

It should be noted that piping is not really necessary here. Rather than assign objects to intermediate steps, we could nest the functions above, producing:

```{r, eval = F}
summarize(group_by(birdCounts, foraging), N = sum(count))
``` 

Take a moment to think of the difference between the piped and nested-function versions of this code. You'll notice that the piped version reads from left-to-right. The dataset becomes progressives smaller with each step to the right. Conversely, the summarize function reads from the inside out. The group_by function is actually the first step in the sequence, but instead it is nested in the middle of the summarize function! When functions are this simple, this likely seems like it's not a big deal. As our data analysis process becomes more complex, however, the nested-function method truly becomes problematically illegible.

----

> **Exercise 7**    
> Give another try to Exercises 1-6 above, this time using piping to complete each in process in one step.
>

----

_**A final note**: You should consider **every** script you write to be not just data analysis but rather a **communication**, between you and your future self and yourself and fellow scientists. Make sure your scripts communicate clearly, future you and your fellow scientists will appreciate it greatly!_

----

<img align = "center" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Git-logo.svg/512px-Git-logo.svg.png" height="150px" width = "150px"/>
