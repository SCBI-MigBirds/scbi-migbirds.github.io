---
  output: html_document
---
  
  <img style="float:right;padding-right:25px;border:none" src="https://upload.wikimedia.org/wikipedia/en/thumb/e/e3/GMU_logo.svg/1280px-GMU_logo.svg.png" height="150px" width = "150px"/>
  
  <img align = "right" src="https://upload.wikimedia.org/wikipedia/en/6/6a/Smithsonian_Conservation_Biology_Institute_logo.png" height="150px" width = "150px"/>
  
# Data manipulation with tidyr and dplyr
##_The grammar of data wrangling_
_Brian S. Evans  
Smithsonian Conservation Biology Institute  
Migratory Bird Center_    
_Note: This lesson borrows **heavily** from Hadley Wickham's awesome paper on Tidy Data (2014). We strongly recommend this paper to all R users!_

## Introduction

  It is estimated that the process of preparing data for analysis, **data manipulation** or, as Hadley Wickham calls it, **data wrangling**, consumes up to 80 percent of total analysis time (Dasu and Johnson 2003).  In classes on statistics and applied data analysis, emphasis is generally placed on the analysis of data and, historically, comparatively little attention is paid to how to prepare one's data to be analyzed. With the expansion of "big data" analysis, however, this is beginning to change. Increasingly, journals are asking authors to publish both data and R code as supplemental information for their manuscripts. This helps advance scientific knownledge, as researchers do not have to reinvent the wheel every time they conduct a similar analysis, and ensures replicability, as interested parties (e.g., reviewers) can repeat your every step in your data analysis with the exception of the collection of field data! 

Considering this, it is in all of our best interest that the data manipulation be simple, that our scripts are legible and easy-to-follow, and that we can avoid "script bloat" by using methods (such as functions and occasionally _for loops_!) to reduce the length of our scripts. It is highly recommended that you take a "cradle-to-grave" approach to data manipulation and analysis:

1) Collect and store your data in well-constructed spreadsheets and databases. 
2) DO NOT complete ANY step in the data manipulation process in Excel! Doing so makes it difficult for others to truly replicate your analyses.
3) **Data tidying** describes basic formatting steps that prepare your data for analysis. Tidying steps be completed prior to any summarizing, further cleaning, or analysis of data.
4) Data cleaning involves removing "bad" records, such as NA values (i.e., "Not Available") and extreme outliers. 
5) Grouping and summarizing data is the final data formatting processes prior to more complex statistical analyses.


## Tidy data

A tidy dataset basically has two qualities -- each row is an observation and each variable is placed in its own column. If you're anything like me, you likely read the last sentence and thought to yourself "well, that's pretty darned obvious -- I don't think I've ever made, nor would I ever make, make an untidy dataset in the first place!" Chances are, you are wrong just as I was. Untidy datasets make their way in all the time. Below is a typical example. You have measured the influence of a treatment on three test subjects and store your results as such:

```{r, eval = T, echo=FALSE}
subject = c('A','B','C')
treatmentA = c(1.3, 2.3, 3.1)
treatmentB = c(2.9, 3.2, 4.6)
untidyFrame <- data.frame(subject, treatmentA, treatmentB)
untidyFrame
```

Tidy? Nope. In this case, each subject has its own row, not each observation. We would have to do some awkward wrangling in base R to get this into a tidy format. Luckily, Hadley Wickham (have we mentioned that we're wicked fans of Hadley Wickham? If not, we will ...) created the _tidyr_ package in R with the specific aim of turning messy datasets into tidy ones.

```{r, eval = T, echo=TRUE, warning=FALSE}
library(tidyr)
```

With the tidyr function _gather_, we collapse multiple columns into "key-value pairs". In the above example, we are interested in the treatment "values" for each of our "key" values. We can tidy the above dataset using:

```{r, eval = T, echo=TRUE}
tidyFrame <- gather(data = untidyFrame, 
                    key = treatment, 
                    value = value, treatmentA:treatmentB)

tidyFrame
```

Let's give a more bird-y example. I (Brian) collected point count data from sites in Washington, D.C. For each bird, I calculated the distance between myself and the individual, in units of 10 meters. On my datasheet I recorded the following:

```{r, eval = T, echo=F, warning=FALSE}
species <- c('amro', 'carw', 'grca')
d10 <- c(0,0,1)
d20 <- c(1,1,0)
d30 <- c(0,0,0)

dFrame <- data.frame(species, d10, d20, d30)

dFrame
```

In the above, each bird is certainly an observation, but is each distance class (which represents 10 to 30 m from the point count location) truly a separate variable? Nope. As such, we are be compelled to collapse our distances to an individual column (if we believe in tidy data), using:

```{r, eval = T, echo=TRUE}
gather(dFrame, distance, obs, d10:d30)
```

The above is what is often called a "long" data frame. Are all tidy data frames long? Heck no! That depends on the observational unit of your study. If your observational unit is individual birds or birds at a given distance class, it may be more appropriate for your data to be arranged in long format. For community data, however, your observational data will likely be site and each column would indeed be its own variable (species). You could always arrange your point count data sheets with each column representing each species that you might possibly encounter at every site of your study ... but then, of course, you'd be crazy. In this instance, the sane among you would collect your data in long format and use wide format for your tidy frame.

_**A final note**: You should consider **every** script you write to be not just data analysis but rather a **communication**, between you and your future self and yourself and fellow scientists. Make sure your scripts communicate clearly, future you and your fellow scientists will appreciate it greatly!_
